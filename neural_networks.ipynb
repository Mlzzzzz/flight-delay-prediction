{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee10791f-9ca0-4669-bf12-dd7a09c14e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f527a80-a193-4a52-9804-1c24ebd5769a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                  int64\n",
       "Quarter               int64\n",
       "Month                 int64\n",
       "DayofMonth            int64\n",
       "DayOfWeek             int64\n",
       "Origin                int64\n",
       "Dest                  int64\n",
       "CRSDepTime            int64\n",
       "CRSArrTime            int64\n",
       "Cancelled           float64\n",
       "Diverted            float64\n",
       "CRSElapsedTime      float64\n",
       "Distance            float64\n",
       "is_holiday_week       int64\n",
       "DepartureDensity    float64\n",
       "ArrivalDensity      float64\n",
       "Visibility          float64\n",
       "WindSpeed           float64\n",
       "SevereWeather         int64\n",
       "BadWeather            int64\n",
       "DepDelay            float64\n",
       "delay_binary          int64\n",
       "delay_interval        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('csv_flight/df_nums.csv')\n",
    "# drop needless columns\n",
    "df = df.drop(columns = ['Tail_Number', 'Flight_Number_Reporting_Airline', 'OriginAirportSeqID', 'TotalDensity', \n",
    "                        'OriginCityName', 'OriginState', 'DestAirportSeqID', 'DestCityName', 'DestState'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1decc60-54cd-43e4-965e-67c2300913ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# non-categorical columns to scale\n",
    "columns_to_scale = ['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime', 'CRSArrTime', 'CRSElapsedTime', \n",
    "                    'Distance', 'DepartureDensity', 'ArrivalDensity', 'Visibility', 'WindSpeed']\n",
    "scaler = StandardScaler()\n",
    "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec2f918-8ff6-414e-8842-2c1613a3535f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CRSElapsedTime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>is_holiday_week</th>\n",
       "      <th>DepartureDensity</th>\n",
       "      <th>ArrivalDensity</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>SevereWeather</th>\n",
       "      <th>BadWeather</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>delay_binary</th>\n",
       "      <th>delay_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.517272</td>\n",
       "      <td>-1.395768</td>\n",
       "      <td>-1.655277</td>\n",
       "      <td>-1.68001</td>\n",
       "      <td>-0.468058</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.431226</td>\n",
       "      <td>-1.514368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.410640</td>\n",
       "      <td>-0.599546</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.018231</td>\n",
       "      <td>-1.752739</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>-0.724781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.517272</td>\n",
       "      <td>-1.395768</td>\n",
       "      <td>-1.655277</td>\n",
       "      <td>-1.68001</td>\n",
       "      <td>-0.468058</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.230794</td>\n",
       "      <td>-1.302969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272470</td>\n",
       "      <td>-0.521488</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.697870</td>\n",
       "      <td>-0.900071</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>-0.724781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.517272</td>\n",
       "      <td>-1.395768</td>\n",
       "      <td>-1.655277</td>\n",
       "      <td>-1.68001</td>\n",
       "      <td>-0.468058</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.216763</td>\n",
       "      <td>-1.332061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.610219</td>\n",
       "      <td>-0.753804</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.665834</td>\n",
       "      <td>-0.729537</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>-0.724781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.517272</td>\n",
       "      <td>-1.395768</td>\n",
       "      <td>-1.655277</td>\n",
       "      <td>-1.68001</td>\n",
       "      <td>-0.468058</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.010318</td>\n",
       "      <td>-0.965507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.938251</td>\n",
       "      <td>1.738485</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.640681</td>\n",
       "      <td>0.748422</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>-1.089562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.517272</td>\n",
       "      <td>-1.395768</td>\n",
       "      <td>-1.655277</td>\n",
       "      <td>-1.68001</td>\n",
       "      <td>-0.468058</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.000297</td>\n",
       "      <td>-0.899566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.383465</td>\n",
       "      <td>2.095323</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.544573</td>\n",
       "      <td>0.748422</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>-1.089562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year   Quarter     Month  DayofMonth  DayOfWeek  Origin  Dest  \\\n",
       "0 -1.517272 -1.395768 -1.655277    -1.68001  -0.468058       0     0   \n",
       "1 -1.517272 -1.395768 -1.655277    -1.68001  -0.468058       0     1   \n",
       "2 -1.517272 -1.395768 -1.655277    -1.68001  -0.468058       0     2   \n",
       "3 -1.517272 -1.395768 -1.655277    -1.68001  -0.468058       0     3   \n",
       "4 -1.517272 -1.395768 -1.655277    -1.68001  -0.468058       0     4   \n",
       "\n",
       "   CRSDepTime  CRSArrTime  Cancelled  Diverted  CRSElapsedTime  Distance  \\\n",
       "0   -1.431226   -1.514368        0.0       0.0       -0.410640 -0.599546   \n",
       "1   -1.230794   -1.302969        0.0       0.0       -0.272470 -0.521488   \n",
       "2   -1.216763   -1.332061        0.0       0.0       -0.610219 -0.753804   \n",
       "3   -1.010318   -0.965507        0.0       0.0        1.938251  1.738485   \n",
       "4   -1.000297   -0.899566        0.0       0.0        2.383465  2.095323   \n",
       "\n",
       "   is_holiday_week  DepartureDensity  ArrivalDensity  Visibility  WindSpeed  \\\n",
       "0                1         -2.018231       -1.752739    0.334387  -0.724781   \n",
       "1                1         -1.697870       -0.900071    0.334387  -0.724781   \n",
       "2                1         -1.665834       -0.729537    0.334387  -0.724781   \n",
       "3                1         -0.640681        0.748422    0.334387  -1.089562   \n",
       "4                1         -0.544573        0.748422    0.334387  -1.089562   \n",
       "\n",
       "   SevereWeather  BadWeather  DepDelay  delay_binary  delay_interval  \n",
       "0              0           0      -3.0             0               0  \n",
       "1              0           0      -2.0             0               0  \n",
       "2              0           0       2.0             0               1  \n",
       "3              0           0      21.0             1               3  \n",
       "4              0           0      -2.0             0               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d43f2474-7c07-40bb-979d-31e3b4d0fa87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1639428, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b9be24-4301-4662-90d4-d53f0a3d507f",
   "metadata": {},
   "source": [
    "#### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "484d7b0e-842b-407a-839f-3d451887d166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c8057fb-193c-490a-b41a-734ef5a10cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delay_binary\n",
      "0    1313698\n",
      "1     325730\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check potential imbalance in the target\n",
    "print(df['delay_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd262937-7de5-4310-a005-f7d8704092b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delay_binary\n",
      "0    325730\n",
      "1    325730\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_majority = df[df['delay_binary'] == 0]\n",
    "df_minority = df[df['delay_binary'] == 1]\n",
    "\n",
    "# downsample majority class\n",
    "df_majority_downsampled = df_majority.sample(n=len(df_minority), random_state=123)\n",
    "# combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "# display new class counts\n",
    "print(df_downsampled['delay_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb597f50-f9e3-45bd-a2f3-21f9dca1983c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: torch.Size([456022, 20])\n",
      "Shape of X_val: torch.Size([97719, 20])\n",
      "Shape of X_test: torch.Size([97719, 20])\n",
      "Shape of y_train: torch.Size([456022])\n",
      "Shape of y_val: torch.Size([97719])\n",
      "Shape of y_test: torch.Size([97719])\n"
     ]
    }
   ],
   "source": [
    "X_downsampled = df_downsampled.iloc[:, 0:20].values\n",
    "y_downsampled = df_downsampled.iloc[:, 21].values\n",
    "\n",
    "# create 70% traning, 15% validation, 15% test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_downsampled, y_downsampled, test_size=0.30, random_state=123)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=123)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a02907fd-af05-4dc6-99dd-e6f150fa5a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1, num_hidden_layers=5):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # first layer\n",
    "        layers = [nn.Linear(input_size, hidden_size)]\n",
    "        nn.init.kaiming_normal_(layers[-1].weight, nonlinearity='leaky_relu')\n",
    "        \n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            nn.init.kaiming_normal_(layers[-1].weight, nonlinearity='leaky_relu')\n",
    "            layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.Dropout(0.5))\n",
    "        \n",
    "        # output layer\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                x = layer(x)\n",
    "                x = F.leaky_relu(x, 0.01) \n",
    "            else:\n",
    "                x = layer(x)\n",
    "        x = self.layers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "055134a1-9ffc-4ba5-bbe9-c507f66b17c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SimpleNN(input_size=20, hidden_size=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=40)\n",
    "loss_function = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdbf84e2-eef0-42b3-ba0b-7d21a3ddf9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.7604, Train Accuracy: 49.94%, Val Loss: 1.7072, Val Accuracy: 49.84%\n",
      "Epoch 201, Train Loss: 0.6393, Train Accuracy: 63.33%, Val Loss: 0.6397, Val Accuracy: 63.01%\n",
      "Epoch 401, Train Loss: 0.6348, Train Accuracy: 63.84%, Val Loss: 0.6365, Val Accuracy: 63.42%\n",
      "Epoch 601, Train Loss: 0.6315, Train Accuracy: 64.22%, Val Loss: 0.6345, Val Accuracy: 63.70%\n",
      "Epoch 801, Train Loss: 0.6299, Train Accuracy: 64.42%, Val Loss: 0.6338, Val Accuracy: 63.93%\n",
      "Epoch 1001, Train Loss: 0.6297, Train Accuracy: 64.49%, Val Loss: 0.6336, Val Accuracy: 63.97%\n",
      "Epoch 1201, Train Loss: 0.6295, Train Accuracy: 64.55%, Val Loss: 0.6335, Val Accuracy: 64.04%\n",
      "Epoch 1401, Train Loss: 0.6290, Train Accuracy: 64.58%, Val Loss: 0.6336, Val Accuracy: 64.02%\n",
      "Epoch 1601, Train Loss: 0.6289, Train Accuracy: 64.57%, Val Loss: 0.6336, Val Accuracy: 64.04%\n",
      "Epoch 1801, Train Loss: 0.6290, Train Accuracy: 64.57%, Val Loss: 0.6336, Val Accuracy: 64.04%\n",
      "Epoch 2001, Train Loss: 0.6290, Train Accuracy: 64.57%, Val Loss: 0.6336, Val Accuracy: 64.04%\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_features, train_labels, val_features, val_labels, optimizer, loss_function, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        train_outputs = model(train_features)\n",
    "        train_loss = loss_function(train_outputs.squeeze(), train_labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(val_features)\n",
    "            val_loss = loss_function(val_outputs.squeeze(), val_labels)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if epoch % 200 == 0:\n",
    "            train_predictions = torch.sigmoid(train_outputs).squeeze() > 0.5\n",
    "            train_correct = (train_predictions == train_labels).sum().item()\n",
    "            train_accuracy = train_correct / len(train_labels)\n",
    "\n",
    "            val_predictions = torch.sigmoid(val_outputs).squeeze() > 0.5\n",
    "            val_correct = (val_predictions == val_labels).sum().item()\n",
    "            val_accuracy = val_correct / len(val_labels)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}, Train Loss: {train_loss.item():.4f}, Train Accuracy: {train_accuracy * 100:.2f}%, '\n",
    "                    f'Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "train(model, X_train, y_train, X_val, y_val, optimizer, loss_function, epochs=2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87f4dbe8-b68e-4d70-9884-a7948f6e03fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6344, Test Accuracy: 63.76%\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_features, test_labels, loss_function):\n",
    "    model.eval() \n",
    "    with torch.no_grad():  \n",
    "        test_outputs = model(test_features)\n",
    "        test_loss = loss_function(test_outputs.squeeze(), test_labels)\n",
    "        test_predictions = torch.sigmoid(test_outputs).squeeze() > 0.5\n",
    "        test_correct = (test_predictions == test_labels).sum().item()\n",
    "        test_accuracy = test_correct / len(test_labels)\n",
    "        \n",
    "    print(f'Test Loss: {test_loss.item():.4f}, Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "    \n",
    "test(model, X_test, y_test, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086baca8-9ab6-41e2-9107-c087aa222d5c",
   "metadata": {},
   "source": [
    "#### Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0681ca7-996b-4b70-bd09-86d69a4d4d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c301929d-3b16-42ab-a7c1-d1ddcc1e5179",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: torch.Size([1147599, 20])\n",
      "Shape of X_val: torch.Size([245914, 20])\n",
      "Shape of X_test: torch.Size([245915, 20])\n",
      "Shape of y_train: torch.Size([1147599])\n",
      "Shape of y_val: torch.Size([245914])\n",
      "Shape of y_test: torch.Size([245915])\n"
     ]
    }
   ],
   "source": [
    "X_downsampled = df.iloc[:, 0:20].values\n",
    "y_downsampled = df.iloc[:, 22].values\n",
    "\n",
    "# create 70% traning, 15% validation, 15% test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_downsampled, y_downsampled, test_size=0.30, random_state=123)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=123)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad537622-cd31-475e-b8ad-1ac331d17efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1, num_hidden_layers=6):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # first layer\n",
    "        layers = [nn.Linear(input_size, hidden_size)]\n",
    "        nn.init.kaiming_normal_(layers[-1].weight, nonlinearity='leaky_relu')\n",
    "        \n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            nn.init.kaiming_normal_(layers[-1].weight, nonlinearity='leaky_relu')\n",
    "            layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.Dropout(0.5))\n",
    "        \n",
    "        # output layer\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                x = layer(x)\n",
    "                x = F.leaky_relu(x, 0.01) \n",
    "            else:\n",
    "                x = layer(x)\n",
    "        x = self.layers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f77c7a8b-848b-42ac-b536-4865b1c0e9c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SimpleNN(input_size=20, hidden_size=64, output_size=9).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=40)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fce13f8f-e0a6-4ea8-9a28-721249c92d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.4583, Train Accuracy: 8.71%, Val Loss: 2.1101, Val Accuracy: 35.81%\n",
      "Epoch 301, Train Loss: 1.3357, Train Accuracy: 58.19%, Val Loss: 1.3382, Val Accuracy: 57.93%\n",
      "Epoch 601, Train Loss: 1.3294, Train Accuracy: 58.20%, Val Loss: 1.3306, Val Accuracy: 57.94%\n",
      "Epoch 901, Train Loss: 1.3273, Train Accuracy: 58.21%, Val Loss: 1.3288, Val Accuracy: 57.95%\n",
      "Epoch 1201, Train Loss: 1.3265, Train Accuracy: 58.21%, Val Loss: 1.3280, Val Accuracy: 57.96%\n",
      "Epoch 1501, Train Loss: 1.3263, Train Accuracy: 58.21%, Val Loss: 1.3279, Val Accuracy: 57.96%\n",
      "Epoch 1801, Train Loss: 1.3263, Train Accuracy: 58.22%, Val Loss: 1.3277, Val Accuracy: 57.96%\n",
      "Epoch 2101, Train Loss: 1.3264, Train Accuracy: 58.21%, Val Loss: 1.3278, Val Accuracy: 57.96%\n",
      "Epoch 2401, Train Loss: 1.3264, Train Accuracy: 58.22%, Val Loss: 1.3278, Val Accuracy: 57.96%\n",
      "Epoch 2701, Train Loss: 1.3264, Train Accuracy: 58.22%, Val Loss: 1.3277, Val Accuracy: 57.96%\n",
      "Epoch 3001, Train Loss: 1.3265, Train Accuracy: 58.21%, Val Loss: 1.3278, Val Accuracy: 57.95%\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_features, train_labels, val_features, val_labels, optimizer, loss_function, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        train_outputs = model(train_features)\n",
    "        train_loss = loss_function(train_outputs, train_labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(val_features)\n",
    "            val_loss = loss_function(val_outputs, val_labels)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if epoch % 300 == 0:\n",
    "            _, train_predictions = torch.max(train_outputs, 1)\n",
    "            train_correct = (train_predictions == train_labels).sum().item()\n",
    "            train_accuracy = train_correct / len(train_labels)\n",
    "            \n",
    "            _, val_predictions = torch.max(val_outputs, 1)\n",
    "            val_correct = (val_predictions == val_labels).sum().item()\n",
    "            val_accuracy = val_correct / len(val_labels)\n",
    "            print(f'Epoch {epoch+1}, Train Loss: {train_loss.item():.4f}, Train Accuracy: {train_accuracy * 100:.2f}%, '\n",
    "                    f'Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "train(model, X_train, y_train, X_val, y_val, optimizer, loss_function, epochs=3001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "450b164d-5b21-49aa-8d60-d33b5486d81e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.3237, Test Accuracy: 58.24%\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_features, test_labels, loss_function):\n",
    "    model.eval() \n",
    "    with torch.no_grad():  \n",
    "        test_outputs = model(test_features)\n",
    "        test_loss = loss_function(test_outputs, test_labels)\n",
    "        _, test_predictions = torch.max(test_outputs, 1)\n",
    "        test_correct = (test_predictions == test_labels).sum().item()\n",
    "        test_accuracy = test_correct / len(test_labels)\n",
    "        \n",
    "    print(f'Test Loss: {test_loss.item():.4f}, Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "    \n",
    "test(model, X_test, y_test, loss_function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
